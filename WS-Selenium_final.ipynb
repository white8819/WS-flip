{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page=driver.get('https://www.naukri.com')\n",
    "\n",
    "# searching for data analysts in Bangalore\n",
    "searchbar=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "searchbar.send_keys(\"Data Analyst\")\n",
    "locationbar=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "locationbar.send_keys(\"Bangalore\")\n",
    "search=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search.click()\n",
    "\n",
    "# time gap for the page to load\n",
    "time.sleep(10)\n",
    "\n",
    "# scrapping data of first 10 jobs\n",
    "job_title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "exp=[]\n",
    "job=driver.find_elements_by_xpath('(//a[@class=\"title fw500 ellipsis\"])[position() < 11]')\n",
    "loc=driver.find_elements_by_xpath('(//li[@class=\"fleft grey-text br2 placeHolderLi location\"])[position() < 11]')\n",
    "comp=driver.find_elements_by_xpath('(//a[@class=\"subTitle ellipsis fleft\"])[position() < 11]')\n",
    "ex=driver.find_elements_by_xpath('(//li[@class=\"fleft grey-text br2 placeHolderLi experience\"])[position() < 11]')\n",
    "\n",
    "# checking length of scrapped data\n",
    "# print(len(job),len(loc),len(comp),len(ex))\n",
    "\n",
    "# getting the texts\n",
    "job_title = [i.text for i in job]\n",
    "location = [i.text for i in loc]\n",
    "company = [i.text for i in comp]\n",
    "exp = [i.text for i in ex]\n",
    "\n",
    "# creating the data frame\n",
    "DA_jobs=pd.DataFrame()\n",
    "DA_jobs['Job_Title']=job_title\n",
    "DA_jobs['Location']=location\n",
    "DA_jobs['Company']=company\n",
    "DA_jobs['Experience']=exp\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# DA_jobs.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immediate opening For Data Scientist/Data Analyst</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst and Data Analyst</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Chennai, Delhi NCR, Bengaluru</td>\n",
       "      <td>Hk solutions</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intern - DFM Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GLOBALFOUNDRIES Engineering Private Limited</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Analysts on Contract Third party p...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reliability Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Alstom Transport India Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Myntra</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Ladder of changes</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Altisource</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst RE) - Bangalore</td>\n",
       "      <td>Bengaluru(Bellandur)</td>\n",
       "      <td>TELEPERFORMANCE GLOBAL SERVICES</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Immediate opening For Data Scientist/Data Analyst   \n",
       "1                  Business Analyst and Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                          Intern - DFM Data Analyst   \n",
       "4  Hiring Data Analysts on Contract Third party p...   \n",
       "5                           Reliability Data Analyst   \n",
       "6                                Senior Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                    Data Analyst / Business Analyst   \n",
       "9            Hiring For Data Analyst RE) - Bangalore   \n",
       "\n",
       "                              Location  \\\n",
       "0  Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1      Delhi NCR, Bengaluru, Hyderabad   \n",
       "2        Chennai, Delhi NCR, Bengaluru   \n",
       "3                            Bengaluru   \n",
       "4                            Bengaluru   \n",
       "5                            Bengaluru   \n",
       "6                            Bengaluru   \n",
       "7                            Bengaluru   \n",
       "8                            Bengaluru   \n",
       "9                 Bengaluru(Bellandur)   \n",
       "\n",
       "                                             Company Experience  \n",
       "0  CAIA-Center For Artificial Intelligence & Adva...    0-3 Yrs  \n",
       "1                                 Tech Mahindra Ltd.   7-12 Yrs  \n",
       "2                                       Hk solutions    0-3 Yrs  \n",
       "3        GLOBALFOUNDRIES Engineering Private Limited    0-5 Yrs  \n",
       "4                  Flipkart Internet Private Limited    2-6 Yrs  \n",
       "5                        Alstom Transport India Ltd.    3-8 Yrs  \n",
       "6                                             Myntra    2-7 Yrs  \n",
       "7                                  Ladder of changes    0-5 Yrs  \n",
       "8                                         Altisource    1-6 Yrs  \n",
       "9                    TELEPERFORMANCE GLOBAL SERVICES    2-6 Yrs  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-5c3b9e76b483>:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for j in tqdm(links):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249466351ef043ffb373223fe12d33bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-senior-data-scientist-groupon-shared-services-pvt-ltd-bengaluru-bangalore-4-to-8-years-231020004338?src=jobsearchDesk&sid=16047454998119301&xp=4&px=1 -- is not a general page. Extracting all text. Scrapped 6405 chars.\n",
      "https://www.naukri.com/job-listings-sr-data-scientist-netapp-india-private-limited-bengaluru-bangalore-10-to-20-years-241020901056?src=jobsearchDesk&sid=16047454998119301&xp=8&px=1 -- is not a general page. Extracting all text. Scrapped 4681 chars.\n",
      "https://www.naukri.com/job-listings-ai-resident-data-scientist-shell-india-markets-private-limited-bengaluru-bangalore-3-to-5-years-051120900454?src=jobsearchDesk&sid=16047454998119301&xp=9&px=1 -- is not a general page. Extracting all text. Scrapped 8645 chars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loading driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page=driver.get('https://www.naukri.com')\n",
    "\n",
    "# searching for data scientists in Bangalore\n",
    "searchbar=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "searchbar.send_keys(\"Data Scientist\")\n",
    "locationbar=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "locationbar.send_keys(\"Bangalore\")\n",
    "search=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search.click()\n",
    "\n",
    "# scrolling to load the page\n",
    "time.sleep(5)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(5)\n",
    "\n",
    "# scrapping data of first 10 jobs\n",
    "job=driver.find_elements_by_xpath('(//a[@class=\"title fw500 ellipsis\"])[position() < 11]')\n",
    "loc=driver.find_elements_by_xpath('(//li[@class=\"fleft grey-text br2 placeHolderLi location\"])[position() < 11]')\n",
    "comp=driver.find_elements_by_xpath('(//a[@class=\"subTitle ellipsis fleft\"])[position() < 11]')\n",
    "\n",
    "# getting the texts\n",
    "job_title = [i.text for i in job]\n",
    "location = [i.text for i in loc]\n",
    "company = [i.text for i in comp]\n",
    "\n",
    "# saving the links for the full JD\n",
    "links = [i.get_attribute('href') for i in job]\n",
    "\n",
    "# checking length of scrapped data\n",
    "# print(len(job_title), len(location), len(comp), len(links))\n",
    "\n",
    "# iterating through the links and extracting the JDs\n",
    "JD=[]\n",
    "for j in tqdm(links):\n",
    "    driver.get(j)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        JD.append(driver.find_elements_by_xpath('//div[@class=\"dang-inner-html\"]')[0].text.replace('\\n', ''))\n",
    "    except:\n",
    "        # if JD is from company sponsored pages, scrape the whole page and extract the relevant information\n",
    "        txt = re.findall(r'Job Description(.*)Content provided by', driver.find_element_by_tag_name('body').text.replace('\\n', ''))[0]\n",
    "        print(f'{j} -- is not a general page. Extracting all text. Scrapped {len(txt)} chars.')\n",
    "        JD.append(txt)\n",
    "\n",
    "# creating the data frame\n",
    "DA_jobs=pd.DataFrame()\n",
    "DA_jobs['Job_Title']=job_title\n",
    "DA_jobs['Location']=location\n",
    "DA_jobs['Company']=company\n",
    "DA_jobs['JD']=JD\n",
    "DA_jobs['links']=links\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# DA_jobs.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>JD</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immediate opening For Data Scientist/Data Analyst</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Dear CandidateSchedule a Telephonic Interview ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-immediate-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>About Data Sciences at Flipkart:The Data Scien...</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist- Computer Vision &amp; Image Proces...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Experience Required: 0 - 6 Years.We are lookin...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Groupon Shared Services</td>\n",
       "      <td>Groupons mission is to become the daily habit ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Chennai, Bengaluru</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Sr. Data Scientist (Min 6 yrs in Data Science/...</td>\n",
       "      <td>https://www.naukri.com/job-listings-sr-data-sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist- Bangalore/ Chennai</td>\n",
       "      <td>Chennai, Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Our Exciting OpportunityWe are looking for Dat...</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>ORMAE LLP</td>\n",
       "      <td>Roles and ResponsibilitiesScientist should hav...</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Job SummaryThis Cloud Business Operations Data...</td>\n",
       "      <td>https://www.naukri.com/job-listings-sr-data-sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AI Resident - Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Job Description:The world faces energy challen...</td>\n",
       "      <td>https://www.naukri.com/job-listings-ai-residen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Roles and ResponsibilitiesIntroductionAs a Dat...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Immediate opening For Data Scientist/Data Analyst   \n",
       "1                              Senior Data Scientist   \n",
       "2  Data Scientist- Computer Vision & Image Proces...   \n",
       "3                              Senior Data Scientist   \n",
       "4                                 Sr. Data Scientist   \n",
       "5          Senior Data Scientist- Bangalore/ Chennai   \n",
       "6                              Senior Data Scientist   \n",
       "7                                 Sr. Data Scientist   \n",
       "8                       AI Resident - Data Scientist   \n",
       "9                                     Data scientist   \n",
       "\n",
       "                              Location  \\\n",
       "0  Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                            Bengaluru   \n",
       "2                            Bengaluru   \n",
       "3                            Bengaluru   \n",
       "4                   Chennai, Bengaluru   \n",
       "5                   Chennai, Bengaluru   \n",
       "6                            Bengaluru   \n",
       "7                            Bengaluru   \n",
       "8                            Bengaluru   \n",
       "9                            Bengaluru   \n",
       "\n",
       "                                             Company  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                                           Flipkart   \n",
       "2                                      24/7 Customer   \n",
       "3                            Groupon Shared Services   \n",
       "4                                       AVE-Promagne   \n",
       "5                             RANDSTAD INDIA PVT LTD   \n",
       "6                                          ORMAE LLP   \n",
       "7                                             NetApp   \n",
       "8                Shell India Markets Private Limited   \n",
       "9                             IBM India Pvt. Limited   \n",
       "\n",
       "                                                  JD  \\\n",
       "0  Dear CandidateSchedule a Telephonic Interview ...   \n",
       "1  About Data Sciences at Flipkart:The Data Scien...   \n",
       "2  Experience Required: 0 - 6 Years.We are lookin...   \n",
       "3  Groupons mission is to become the daily habit ...   \n",
       "4  Sr. Data Scientist (Min 6 yrs in Data Science/...   \n",
       "5  Our Exciting OpportunityWe are looking for Dat...   \n",
       "6  Roles and ResponsibilitiesScientist should hav...   \n",
       "7  Job SummaryThis Cloud Business Operations Data...   \n",
       "8  Job Description:The world faces energy challen...   \n",
       "9  Roles and ResponsibilitiesIntroductionAs a Dat...   \n",
       "\n",
       "                                               links  \n",
       "0  https://www.naukri.com/job-listings-immediate-...  \n",
       "1  https://www.naukri.com/job-listings-senior-dat...  \n",
       "2  https://www.naukri.com/job-listings-data-scien...  \n",
       "3  https://www.naukri.com/job-listings-senior-dat...  \n",
       "4  https://www.naukri.com/job-listings-sr-data-sc...  \n",
       "5  https://www.naukri.com/job-listings-senior-dat...  \n",
       "6  https://www.naukri.com/job-listings-senior-dat...  \n",
       "7  https://www.naukri.com/job-listings-sr-data-sc...  \n",
       "8  https://www.naukri.com/job-listings-ai-residen...  \n",
       "9  https://www.naukri.com/job-listings-data-scien...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# loading the driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page = driver.get('https://www.naukri.com')\n",
    "\n",
    "# searching for data scientists\n",
    "searchbar = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "searchbar.send_keys(\"Data Scientist\")\n",
    "search = driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search.click()\n",
    "\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@id=\"chk-Delhi/NCR-cityType-\"]').find_element_by_xpath('..').click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@id=\"chk-3-6 Lakhs-ctcFilter-\"]').find_element_by_xpath('..').click()\n",
    "time.sleep(5)\n",
    "\n",
    "# scrapping data of first 10 jobs:\n",
    "job = driver.find_elements_by_xpath('(//a[@class=\"title fw500 ellipsis\"])[position() < 11]')\n",
    "loc = driver.find_elements_by_xpath('(//li[@class=\"fleft grey-text br2 placeHolderLi location\"])[position() < 11]')\n",
    "comp = driver.find_elements_by_xpath('(//a[@class=\"subTitle ellipsis fleft\"])[position() < 11]')\n",
    "ex = driver.find_elements_by_xpath('(//li[@class=\"fleft grey-text br2 placeHolderLi experience\"])[position() < 11]')\n",
    "\n",
    "# getting the relevant text\n",
    "job_title = [i.text for i in job]\n",
    "location = [i.text for i in loc]\n",
    "company = [i.text for i in comp]\n",
    "exp = [i.text for i in ex]\n",
    "\n",
    "# check the lenght of scrapped texts\n",
    "# print(len(job_title), len(location), len(comp), len(ex))\n",
    "\n",
    "# creating the data frame\n",
    "DA_jobs=pd.DataFrame()\n",
    "DA_jobs['Job_Title'] = job_title\n",
    "DA_jobs['Location'] = location\n",
    "DA_jobs['Company'] = company\n",
    "DA_jobs['exp'] = exp\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# DA_jobs.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Delhi NCR, Ghaziabad, Gurgaon</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Faridabad, Delhi NCR, Greater Noida</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>WellMed Medical Management</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/Analyst - Machine Learning/Deep...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>EchoIndia</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - NLP/ML/Python</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>Elixir Web Solutions</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - NLP/ML/Python</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>Elixir Web Solutions</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>GlobalHunt India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Blue Sky Analytics</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist/BPM/4-8 years</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Crescendo global services</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "2                           Associate Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4  Data Scientist/Analyst - Machine Learning/Deep...   \n",
       "5                     Data Scientist - NLP/ML/Python   \n",
       "6                     Data Scientist - NLP/ML/Python   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                       Data Scientist/BPM/4-8 years   \n",
       "\n",
       "                              Location  \\\n",
       "0        Delhi NCR, Ghaziabad, Gurgaon   \n",
       "1  Faridabad, Delhi NCR, Greater Noida   \n",
       "2                                Noida   \n",
       "3                                Noida   \n",
       "4                                Delhi   \n",
       "5                     Gurgaon Gurugram   \n",
       "6                     Gurgaon Gurugram   \n",
       "7                                Delhi   \n",
       "8                              Gurgaon   \n",
       "9                              Gurgaon   \n",
       "\n",
       "                                  Company      exp  \n",
       "0               GABA Consultancy services  0-0 Yrs  \n",
       "1               GABA Consultancy services  0-0 Yrs  \n",
       "2              WellMed Medical Management  4-8 Yrs  \n",
       "3  AlgoScale Technologies Private Limited  1-5 Yrs  \n",
       "4                               EchoIndia  3-6 Yrs  \n",
       "5                    Elixir Web Solutions  4-8 Yrs  \n",
       "6                    Elixir Web Solutions  4-8 Yrs  \n",
       "7        GlobalHunt India Private Limited  3-6 Yrs  \n",
       "8                      Blue Sky Analytics  1-6 Yrs  \n",
       "9               Crescendo global services  4-7 Yrs  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page=driver.get('https://www.glassdoor.co.in/index.htm')\n",
    "\n",
    "# sign-in\n",
    "driver.find_element_by_xpath('//*[@class=\"locked-home-sign-in\"]').click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@for=\"userEmail\"]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"userEmail\"]').send_keys('ltg18198@eoopy.com')\n",
    "driver.find_element_by_xpath('//*[@for=\"userPassword\"]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"userPassword\"]').send_keys('GW9pBgVvpX9C2Wc')\n",
    "driver.find_element_by_xpath('//*[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "time.sleep(10)\n",
    "\n",
    "# search for data scientist\n",
    "driver.execute_script(\"document.getElementById('sc.keyword').click()\")\n",
    "driver.find_element_by_id('sc.keyword').send_keys(Keys.CONTROL + \"a\")\n",
    "driver.find_element_by_id('sc.keyword').send_keys(Keys.DELETE)\n",
    "driver.find_element_by_id('sc.keyword').send_keys('Data Scientist')\n",
    "\n",
    "# search for data noida\n",
    "driver.find_element_by_id('sc.location').send_keys(Keys.CONTROL + \"a\");\n",
    "driver.find_element_by_id('sc.location').send_keys(Keys.DELETE)\n",
    "driver.find_element_by_id('sc.location').send_keys('Noida (India)')\n",
    "\n",
    "# press enter\n",
    "driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "time.sleep(20)\n",
    "\n",
    "# get the top 10 listing\n",
    "company = [i.text for i in driver.find_elements_by_xpath('(//*[@class=\"jobHeader d-flex justify-content-between align-items-start\"])[position() < 11]')]\n",
    "role = [i.text for i in driver.find_elements_by_xpath('(//*[@class=\"jobInfoItem jobTitle css-13w0lq6 eigr9kq1 jobLink\"])[position() < 11]')]\n",
    "days = [i.text for i in driver.find_elements_by_xpath('(//*[@class=\"d-flex align-items-end pl-std css-mi55ob\"])[position() < 11]')]\n",
    "stars = [i.text for i in driver.find_elements_by_xpath('(//*[@class=\"compactStars \"])[position() < 11]')]\n",
    "\n",
    "#Creating the data frame\n",
    "DA_jobs = pd.DataFrame()\n",
    "DA_jobs['Company'] = company\n",
    "DA_jobs['Role'] = role\n",
    "DA_jobs['Days Ago'] = days\n",
    "DA_jobs['Star'] = stars\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# DA_jobs.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Role</th>\n",
       "      <th>Days Ago</th>\n",
       "      <th>Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Express Global Business Travel</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>23d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>25d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algoscale</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>16d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>16d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brickred</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>7d</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>22d</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Healtheoz India</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>16d</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jubna</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Company            Role Days Ago Star\n",
       "0                       Ericsson-Worldwide  Data Scientist       4d    4\n",
       "1  American Express Global Business Travel  Data Scientist      23d  3.7\n",
       "2                                      IBM  Data Scientist       1d  3.9\n",
       "3                           Biz2Credit Inc  Data Scientist      25d  3.7\n",
       "4                                Algoscale  Data Scientist      16d  3.7\n",
       "5                          SearchUrCollege  Data Scientist      16d  3.7\n",
       "6                                 Brickred  Data Scientist       7d    5\n",
       "7                                 Techlive  Data Scientist      22d  4.8\n",
       "8                          Healtheoz India  Data Scientist      16d    3\n",
       "9                                    Jubna  Data Scientist       6d  3.1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page=driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "time.sleep(5)\n",
    "\n",
    "# searching for salaries of data sicentists in Noida\n",
    "driver.find_element_by_id('KeywordSearch').send_keys(Keys.DELETE)\n",
    "driver.find_element_by_id('KeywordSearch').send_keys('Data Scientist')\n",
    "\n",
    "driver.find_element_by_id('LocationSearch').send_keys(Keys.CONTROL + \"a\");\n",
    "driver.find_element_by_id('LocationSearch').send_keys(Keys.DELETE)\n",
    "driver.find_element_by_id('LocationSearch').send_keys('Noida')\n",
    "\n",
    "driver.find_element_by_xpath('//*[@class=\"gd-btn-mkt\"]').click()\n",
    "time.sleep(10)\n",
    "\n",
    "# Getting the salary details of the first 10 companies\n",
    "details = [i.text.split('\\n') if len(i.text.split('\\n'))==8 \n",
    "           else i.text.split('\\n')[1:] # skipping 'is it helpful' text\n",
    "           for i in driver.find_elements_by_xpath('(//*[@data-test=\"salary-list-items\"][position() < 11])')]\n",
    "\n",
    "salaries_df = pd.DataFrame([(i[1], \n",
    "                             i[4], \n",
    "                             i[-2], \n",
    "                             i[-1], \n",
    "                             ' '.join(i[3].split()[1:3])) \n",
    "                            for i in details], \n",
    "                           columns=['Company', 'Average', 'Min', 'Max', '# Salaries'])\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# salaries_df.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Average</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th># Salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 13,18,563</td>\n",
       "      <td>₹706K</td>\n",
       "      <td>₹11,513K</td>\n",
       "      <td>12 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 9,85,497</td>\n",
       "      <td>₹572K</td>\n",
       "      <td>₹1,300K</td>\n",
       "      <td>29 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 7,53,602</td>\n",
       "      <td>₹581K</td>\n",
       "      <td>₹2,704K</td>\n",
       "      <td>59 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,23,634</td>\n",
       "      <td>₹710K</td>\n",
       "      <td>₹1,559K</td>\n",
       "      <td>12 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹ 9,97,979</td>\n",
       "      <td>₹785K</td>\n",
       "      <td>₹1,251K</td>\n",
       "      <td>38 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 7,72,507</td>\n",
       "      <td>₹497K</td>\n",
       "      <td>₹1,140K</td>\n",
       "      <td>9 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vidooly Media Tech</td>\n",
       "      <td>₹ 12,689</td>\n",
       "      <td>₹8K</td>\n",
       "      <td>₹20K</td>\n",
       "      <td>10 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>₹ 21,215</td>\n",
       "      <td>₹14K</td>\n",
       "      <td>₹22K</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,77,498</td>\n",
       "      <td>₹480K</td>\n",
       "      <td>₹1,000K</td>\n",
       "      <td>60 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,34,456</td>\n",
       "      <td>₹460K</td>\n",
       "      <td>₹1,598K</td>\n",
       "      <td>15 salaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company      Average    Min       Max   # Salaries\n",
       "0                       Delhivery  ₹ 13,18,563  ₹706K  ₹11,513K  12 salaries\n",
       "1                       Accenture   ₹ 9,85,497  ₹572K   ₹1,300K  29 salaries\n",
       "2                             IBM   ₹ 7,53,602  ₹581K   ₹2,704K  59 salaries\n",
       "3              UnitedHealth Group  ₹ 13,23,634  ₹710K   ₹1,559K  12 salaries\n",
       "4  Cognizant Technology Solutions   ₹ 9,97,979  ₹785K   ₹1,251K  38 salaries\n",
       "5              Valiance Solutions   ₹ 7,72,507  ₹497K   ₹1,140K   9 salaries\n",
       "6              Vidooly Media Tech     ₹ 12,689    ₹8K      ₹20K  10 salaries\n",
       "7                Analytics Vidhya     ₹ 21,215   ₹14K      ₹22K   7 salaries\n",
       "8       Tata Consultancy Services   ₹ 6,77,498  ₹480K   ₹1,000K  60 salaries\n",
       "9              Ericsson-Worldwide   ₹ 7,34,456  ₹460K   ₹1,598K  15 salaries"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6fad4d93da4608a4b874e07fbb2171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407e084c0fc8499781412dc0ed5270a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdc0e52e51341289c8bee17d158749c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loading driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page = driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# key in the sunglass as search term and press search\n",
    "driver.find_element_by_xpath('//*[@class=\"_2AkmmA _29YdH8\"]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input').send_keys('sunglasses')\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()\n",
    "time.sleep(10)\n",
    "\n",
    "# create empty lists for scraping the details\n",
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "discount = []\n",
    "\n",
    "# loop to scrape one page after another\n",
    "while True:\n",
    "    # get all the webdriver objects for the listed items\n",
    "    items = driver.find_elements_by_xpath('//*[@class=\"IIdQZO _1SSAGr\"]')\n",
    "    \n",
    "    # loop in all the objects and extract the details\n",
    "    for item in tqdm(items):\n",
    "        \n",
    "        # get the brand\n",
    "        try:\n",
    "            brand.append(item.find_element_by_class_name('_2B_pmu').text)\n",
    "        except:\n",
    "            brand.append('NA')\n",
    "\n",
    "        # get the description\n",
    "        try:\n",
    "            desc.append(item.find_element_by_class_name('_2mylT6').text)\n",
    "        except:\n",
    "            desc.append('NA')\n",
    "\n",
    "        # get the price\n",
    "        try:\n",
    "            price.append(item.find_element_by_class_name('_1vC4OE').text)\n",
    "        except:\n",
    "            price.append('NA')\n",
    "\n",
    "        # get the discount\n",
    "        try:\n",
    "            discount.append(item.find_element_by_class_name('VGWI6T').text)\n",
    "        except:\n",
    "            discount.append('NA')\n",
    "    \n",
    "    # if the length of the scrapped items exceeded 100, break\n",
    "    if(len(brand) >= 100):\n",
    "        break\n",
    "    \n",
    "    # else, go to next page and repeat\n",
    "    driver.find_element_by_class_name('_3fVaIS').click()\n",
    "    time.sleep(10)\n",
    "\n",
    "# creating the data frame\n",
    "sunglass = pd.DataFrame()\n",
    "sunglass['Brand'] = brand[:100]\n",
    "sunglass['desc'] = desc[:100]\n",
    "sunglass['Price'] = price[:100]\n",
    "sunglass['Discount'] = discount[:100]\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# salaries_df.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Colors of Benetton</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (57)</td>\n",
       "      <td>₹1,755</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Colors of Benetton</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (56)</td>\n",
       "      <td>₹1,755</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹809</td>\n",
       "      <td>10% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹312</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹206</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>United Colors of Benetton</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹4,500</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>winsome</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹130</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹312</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Gradient, UV Protection Round Sungl...</td>\n",
       "      <td>₹403</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Brand  \\\n",
       "0   United Colors of Benetton   \n",
       "1   United Colors of Benetton   \n",
       "2                    Fastrack   \n",
       "3                   Elligator   \n",
       "4                      PIRASO   \n",
       "..                        ...   \n",
       "95  United Colors of Benetton   \n",
       "96                    winsome   \n",
       "97                 Phenomenal   \n",
       "98           shah collections   \n",
       "99             ROZZETTA CRAFT   \n",
       "\n",
       "                                                 desc   Price Discount  \n",
       "0          UV Protection Retro Square Sunglasses (57)  ₹1,755  55% off  \n",
       "1     Mirrored, UV Protection Aviator Sunglasses (56)  ₹1,755  55% off  \n",
       "2       UV Protection Wayfarer Sunglasses (Free Size)    ₹809  10% off  \n",
       "3                 UV Protection Round Sunglasses (54)    ₹312  87% off  \n",
       "4               UV Protection Aviator Sunglasses (54)    ₹206  87% off  \n",
       "..                                                ...     ...      ...  \n",
       "95                  Mirrored Wayfarer Sunglasses (56)  ₹4,500       NA  \n",
       "96                UV Protection Round Sunglasses (54)    ₹130  73% off  \n",
       "97  UV Protection, Mirrored Retro Square Sunglasse...    ₹399  80% off  \n",
       "98         UV Protection Round Sunglasses (Free Size)    ₹312  75% off  \n",
       "99  Polarized, Gradient, UV Protection Round Sungl...    ₹403  79% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76f8af6af9d44f5be5ff26895384595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c52ea77d16643fba80547a2242c7311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a2f93995224970ba1aa996b54a2aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623c20d1b11e4fb0834bd59a6b51708e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd812d44dc54150a3184006cd04b309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fce5664e2a84cbb8bc0f18b537f3f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeb73ad63b24aa7847c8dadd0326ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1318a3cf804a8fbe7344cd43e32053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bbbfd5fb904557a4adc5e683fa7880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511e5eb91e82468c83afce107a4545e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page = driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "\n",
    "# show all reviews\n",
    "driver.find_element_by_class_name('swINJg').click()\n",
    "time.sleep(10)\n",
    "\n",
    "# create empty lists for scraping the details\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "p = 1\n",
    "\n",
    "# loop to scrape one page after another\n",
    "while True:\n",
    "    # get all the webdriver objects for the listed items\n",
    "    items =  driver.find_elements_by_class_name('_3gijNv')[6:-1]\n",
    "    \n",
    "    # loop in all the objects and extract the details\n",
    "    for item in tqdm(items):\n",
    "        \n",
    "        # get the rating\n",
    "        try:\n",
    "            Rating.append(item.find_element_by_class_name('hGSR34').text)\n",
    "        except:\n",
    "            Rating.append('NA')\n",
    "        \n",
    "        # get the review summary\n",
    "        try:\n",
    "            Review_summary.append(item.find_element_by_class_name('_2xg6Ul').text)\n",
    "        except:\n",
    "            Review_summary.append('NA')\n",
    "\n",
    "        # get the full review\n",
    "        try:\n",
    "            Full_review.append(item.find_element_by_class_name('qwjRop').text)\n",
    "        except:\n",
    "            Full_review.append('NA')\n",
    "\n",
    "    # increase the page number and append it to the url to retrive the next page\n",
    "    p += 1\n",
    "    driver.get(driver.current_url + f'&page={p}')\n",
    "    \n",
    "    # break out if already 100 reviews are scrapped\n",
    "    if(len(Rating) >= 100):\n",
    "        break\n",
    "    \n",
    "\n",
    "# creating the data frame\n",
    "reviews = pd.DataFrame()\n",
    "reviews['Rating'] = Rating\n",
    "reviews['Review_summary'] = Review_summary\n",
    "reviews['Full_review'] = Full_review\n",
    "\n",
    "reviews = reviews.drop_duplicates().iloc[:100]\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# reviews.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Terrific!!! Lucky to get this phone in first l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Iphone 11 black 64gb is really a cool phone\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Although it’s an iPhone, it doesn’t give anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Apple i Phone is the best phone available in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>use outside gives a outstanding experience ......</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review_summary  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5    Perfect product!   \n",
       "3       5  Highly recommended   \n",
       "4       5    Perfect product!   \n",
       "..    ...                 ...   \n",
       "95      5       Great product   \n",
       "96      3                Nice   \n",
       "97      3                Nice   \n",
       "98      5           Just wow!   \n",
       "99      5           Brilliant   \n",
       "\n",
       "                                          Full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   It’s a must buy who is looking for an upgrade ...  \n",
       "3   iphone 11 is a very good phone to buy only if ...  \n",
       "4   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                ...  \n",
       "95  Terrific!!! Lucky to get this phone in first l...  \n",
       "96  Iphone 11 black 64gb is really a cool phone\\n\\...  \n",
       "97  Although it’s an iPhone, it doesn’t give anyth...  \n",
       "98  Apple i Phone is the best phone available in t...  \n",
       "99  use outside gives a outstanding experience ......  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283936652329413481686935599e2dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23efdefeefaf48b4aa03745dad09396f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684c5d5c857547f997b0004a3fcb8560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loading driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page=driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# search for sneakers\n",
    "driver.find_element_by_xpath('//*[@class=\"_2AkmmA _29YdH8\"]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input').send_keys('sneakers')\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()\n",
    "time.sleep(10)\n",
    "\n",
    "# create empty lists for scraping the details\n",
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "discount = []\n",
    "\n",
    "# loop to scrape one page after another\n",
    "while True:\n",
    "    \n",
    "    # get all the webdriver objects for the listed items\n",
    "    items = driver.find_elements_by_xpath('//*[@class=\"IIdQZO _1SSAGr\"]')\n",
    "    \n",
    "    # loop in all the objects and extract the details\n",
    "    for item in tqdm(items):\n",
    "        \n",
    "        # get the brand\n",
    "        try:\n",
    "            brand.append(item.find_element_by_class_name('_2B_pmu').text)\n",
    "        except:\n",
    "            brand.append('NA')\n",
    "\n",
    "        # get the description\n",
    "        try:\n",
    "            desc.append(item.find_element_by_class_name('_2mylT6').text)\n",
    "        except:\n",
    "            desc.append('NA')\n",
    "\n",
    "        # get the price\n",
    "        try:\n",
    "            price.append(item.find_element_by_class_name('_1vC4OE').text)\n",
    "        except:\n",
    "            price.append('NA')\n",
    "\n",
    "        # get the discount\n",
    "        try:\n",
    "            discount.append(item.find_element_by_class_name('VGWI6T').text)\n",
    "        except:\n",
    "            discount.append('NA')\n",
    "            \n",
    "    # break out if already 100 reviews are scrapped\n",
    "    if(len(brand) >= 100):\n",
    "        break\n",
    "    driver.find_element_by_class_name('_3fVaIS').click()\n",
    "    time.sleep(10)\n",
    "\n",
    "# creating the data frame\n",
    "sneakers = pd.DataFrame()\n",
    "sneakers['Brand'] = brand[:100]\n",
    "sneakers['desc'] = desc[:100]\n",
    "sneakers['Price'] = price[:100]\n",
    "sneakers['Discount'] = discount[:100]\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# sneakers.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ducati</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ducati</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹461</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Chevit Latest Fashion Combo Pack of 2 Pairs Ca...</td>\n",
       "      <td>₹525</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>WROGN</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,679</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack of 5 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Smart Casuals Canvas Shoes Combo pack of 2 Sne...</td>\n",
       "      <td>₹360</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Provogue</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                               desc   Price  \\\n",
       "0      Ducati                                   Sneakers For Men  ₹1,999   \n",
       "1      Ducati                                   Sneakers For Men  ₹1,999   \n",
       "2      Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹461   \n",
       "3      Chevit  Chevit Latest Fashion Combo Pack of 2 Pairs Ca...    ₹525   \n",
       "4      Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...    ₹236   \n",
       "..        ...                                                ...     ...   \n",
       "95      WROGN                                   Sneakers For Men  ₹1,679   \n",
       "96     BRUTON  Combo Pack of 5 Casual Sneakers With Sneakers ...    ₹699   \n",
       "97     Chevit  Smart Casuals Canvas Shoes Combo pack of 2 Sne...    ₹360   \n",
       "98  Rockfield                                   Sneakers For Men    ₹499   \n",
       "99   Provogue                                   Sneakers For Men    ₹549   \n",
       "\n",
       "   Discount  \n",
       "0   45% off  \n",
       "1   45% off  \n",
       "2   76% off  \n",
       "3   64% off  \n",
       "4   52% off  \n",
       "..      ...  \n",
       "95  40% off  \n",
       "96  82% off  \n",
       "97  63% off  \n",
       "98  50% off  \n",
       "99  57% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "# loading webpage onto driver\n",
    "my_page=driver.get('https://www.myntra.com/shoes')\n",
    "\n",
    "# setting in the filters for price range and color\n",
    "driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label').click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label').click()\n",
    "time.sleep(5)\n",
    "\n",
    "# create empty lists for scraping the details \n",
    "brand = []\n",
    "desc = []\n",
    "price = []\n",
    "\n",
    "# loop to scrape one page after another\n",
    "while True:\n",
    "    \n",
    "    # get all the webdriver objects for the listed items\n",
    "    items = driver.find_elements_by_class_name('product-base')\n",
    "    \n",
    "    # loop in all the objects and extract the details\n",
    "    for item in tqdm(items):\n",
    "        \n",
    "        # get the brand\n",
    "        try:\n",
    "            brand.append(item.find_element_by_class_name('product-brand').text)\n",
    "        except:\n",
    "            brand.append('NA')\n",
    "\n",
    "        # get the desc\n",
    "        try:\n",
    "            desc.append(item.find_element_by_class_name('product-product').text)\n",
    "        except:\n",
    "            desc.append('NA')\n",
    "            \n",
    "        # get the discounted price\n",
    "        try:\n",
    "            price.append(item.find_element_by_class_name('product-discountedPrice').text)\n",
    "        except:\n",
    "            # if discounted price does not exist, get the base price\n",
    "            try:\n",
    "                price.append(item.find_element_by_class_name('product-price').text)\n",
    "            except:\n",
    "                price.append('NA')\n",
    "             \n",
    "    # break out if already 100 reviews are scrapped\n",
    "    if(len(brand) >= 100):\n",
    "        break\n",
    "    \n",
    "    # go to the next page\n",
    "    driver.find_element_by_class_name('pagination-next').click()\n",
    "    time.sleep(10)\n",
    "\n",
    "# creating the data frame\n",
    "shoes = pd.DataFrame()\n",
    "shoes['Brand'] = brand[:100]\n",
    "shoes['desc'] = desc[:100]\n",
    "shoes['Price'] = price[:100]\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# shoes.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366a5c79a5e444a6af81db7e2dcdb923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3627f48e50c45db818f05a19de8ac99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Questar Flow Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Running Shoes</td>\n",
       "      <td>Rs. 7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Training Shoes</td>\n",
       "      <td>Rs. 6795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Solid AR Training Shoes</td>\n",
       "      <td>Rs. 7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women Edge Lux 4 Running Shoes</td>\n",
       "      <td>Rs. 7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "      <td>Rs. 12990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 9499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Heeled Boots</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                            desc      Price\n",
       "0             ADIDAS       Men Questar Flow Sneakers   Rs. 6999\n",
       "1               Nike          Men Zoom Running Shoes   Rs. 7995\n",
       "2               Nike              Men Training Shoes   Rs. 6795\n",
       "3               ALDO    Men Textured Leather Loafers  Rs. 12999\n",
       "4   ADIDAS Originals     Men Solid AR Training Shoes   Rs. 7199\n",
       "..               ...                             ...        ...\n",
       "95            ADIDAS  Women Edge Lux 4 Running Shoes   Rs. 7199\n",
       "96              Geox       Men Leather Formal Derbys  Rs. 12990\n",
       "97            Clarks      Men Leather Formal Loafers   Rs. 6999\n",
       "98              Puma             Women Running Shoes   Rs. 9499\n",
       "99    Tommy Hilfiger              Women Heeled Boots   Rs. 7999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4defd582a9524231922fbbaac5121bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loading driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "#loading webpage onto driver\n",
    "my_page=driver.get('https://www.amazon.in')\n",
    "\n",
    "# key in the laptop for searching\n",
    "driver.find_element_by_class_name('nav-input').send_keys('laptop')\n",
    "driver.find_element_by_class_name('nav-search-submit-text').click()\n",
    "time.sleep(5)\n",
    "\n",
    "# set the filters for i7 and i9 processors\n",
    "driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span').click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/span').click()\n",
    "time.sleep(5)\n",
    "\n",
    "# create empty lists for scraping the details \n",
    "title = []\n",
    "rating = []\n",
    "price = []\n",
    "\n",
    "# get all the webdriver objects for the listed items\n",
    "items = driver.find_elements_by_xpath('(//*[contains(@class, \"sg-col-20-of-24 s-result-item s-asin sg-col-0-of-12 sg-col-28-of-32 sg-col-16-of-20\")])[position() < 11]')\n",
    "\n",
    "# loop in all the objects and extract the details\n",
    "for item in tqdm(items):\n",
    "    \n",
    "    # get the title\n",
    "    try:\n",
    "        title.append(item.find_element_by_xpath('.//span[@class=\"a-size-medium a-color-base a-text-normal\"]').text)\n",
    "    except:\n",
    "        title.append('NA')\n",
    "\n",
    "    # get the rating\n",
    "    try:\n",
    "        rating.append(item.find_element_by_xpath('.//span[@class=\"a-size-base\"]').text)\n",
    "    except:\n",
    "        rating.append('NA')\n",
    "        \n",
    "    # get the price\n",
    "    try:\n",
    "        price.append(item.find_element_by_xpath('.//span[@class=\"a-price\"]').text)\n",
    "    except:\n",
    "        price.append('NA')\n",
    "         \n",
    "# creating the data frame\n",
    "laptops = pd.DataFrame()\n",
    "laptops['title'] = title[:100]\n",
    "laptops['rating'] = rating[:100]\n",
    "laptops['Price'] = price[:100]\n",
    "laptops['Price'] = laptops.Price.str.replace('\\n', '.')\n",
    "\n",
    "# closing the driver\n",
    "driver.close()\n",
    "\n",
    "# saving the file in csv format\n",
    "# laptops.to_csv('DataAnalyst_jobs.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>10</td>\n",
       "      <td>₹1,99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6-inch FHD Laptop (10th...</td>\n",
       "      <td>7</td>\n",
       "      <td>₹85,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>10</td>\n",
       "      <td>₹1,99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) ASUS ZenBook Duo Intel Core i7-10510...</td>\n",
       "      <td>NA</td>\n",
       "      <td>₹1,05,739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) Lenovo Yoga S740 Intel Core i7 10th ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>₹93,492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Inspiron 5501 15.6 Inch FHD Lap...</td>\n",
       "      <td>NA</td>\n",
       "      <td>₹73,092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td>170</td>\n",
       "      <td>₹82,789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E7240 12.5-inch Laptop...</td>\n",
       "      <td>12</td>\n",
       "      <td>₹39,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) HP Omen 10th Gen Intel Core i7 Proce...</td>\n",
       "      <td>NA</td>\n",
       "      <td>₹97,742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>22</td>\n",
       "      <td>₹1,29,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title rating      Price\n",
       "0  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...     10  ₹1,99,990\n",
       "1  Dell G3 3500 Gaming 15.6-inch FHD Laptop (10th...      7    ₹85,590\n",
       "2  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...     10  ₹1,99,990\n",
       "3  (Renewed) ASUS ZenBook Duo Intel Core i7-10510...     NA  ₹1,05,739\n",
       "4  (Renewed) Lenovo Yoga S740 Intel Core i7 10th ...     NA    ₹93,492\n",
       "5  (Renewed) Dell Inspiron 5501 15.6 Inch FHD Lap...     NA    ₹73,092\n",
       "6  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...    170    ₹82,789\n",
       "7  (Renewed) Dell Latitude E7240 12.5-inch Laptop...     12    ₹39,999\n",
       "8  (Renewed) HP Omen 10th Gen Intel Core i7 Proce...     NA    ₹97,742\n",
       "9  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...     22  ₹1,29,990"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
